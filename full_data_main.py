import os
import matplotlib.pyplot as plt
import tensorflow as tf
import pathlib
from skimage.color import rgb2gray
from keras.callbacks import ModelCheckpoint

from models import *
from utils import *
from xai_trans import *

set_seed(0)

SET_PERCENT = 1

dataset_dir = './dataset/malevis_train_val_224x224/gyumin_2_train/'
dataset_dir = pathlib.Path(dataset_dir)

train_ds = tf.keras.utils.image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,
    subset="training",
    seed=1,
    color_mode='grayscale',
    batch_size=64)

test_ds = tf.keras.utils.image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,
    subset="validation",
    seed=1,
    color_mode='grayscale',
    batch_size=64,
    shuffle=True)

print(type(train_ds))
for x, y in train_ds.take(1):
    print(x.shape)
print(train_ds)
exit()

# 데이터 전처리 1 / 255
normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)

normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
normalized_test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))

# x_train = tf.concat([x for x, y in normalized_train_ds], axis=0)
# y_train = tf.concat([y for x, y in normalized_train_ds], axis=0)

# x_test = tf.concat([x for x, y in normalized_test_ds], axis=0)
# y_test = tf.concat([y for x, y in normalized_test_ds], axis=0)

os.makedirs(f'./models', exist_ok=True)
if exists(f'./models/saved_model.pb'):
    model = tf.keras.models.load_model('./models/')
else:
    model = base_CNN()

    model.compile(
        optimizer='adam',
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=['accuracy'])

    checkpoint_path = f'./models/'
    # MNIST 학습 checkpoint
    checkpoint = ModelCheckpoint(checkpoint_path,
                                save_best_only=True,
                                save_weights_only=True,
                                monitor='val_accuracy',
                                verbose=1)

    model.compile(optimizer='adam',
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])

    # model.fit(normalized_train_ds, epochs=10, shuffle=True, validation_data= normalized_test_ds, callbacks=[checkpoint],)
    model.fit(x_train, y_train, epochs=10, batch_size=64, shuffle=True, validation_data=(x_test, y_test), callbacks=[checkpoint],)

    model.save(checkpoint_path)

print(model.evaluate(x_train, y_train))
print(model.evaluate(x_test, y_test))

exit()
# XAI 데이터셋 생성
if exists(f'./dataset/malevis_224_ig_train') and exists(f'./dataset/malevis_224_ig_test'):
    x_train_ig = pickle.load(open(f'./dataset/malevis_224_ig_train','rb'))
    x_test_ig = pickle.load(open(f'./dataset/malevis_224_ig_test','rb'))
else:
    x_train_ig = transf_ig('malevis_224_ig_train', model, normalized_train_ds)
    x_test_ig = transf_ig('malevis_224_ig_test', model, normalized_test_ds)

for img, label in normalized_test_ds.take(1):
    for i in range(10):
        plt.imshow(img[i])
        plt.savefig(f'./img/{i}.png')

for i in range(10):
    plt.imshow(x_test_ig[i])
    plt.savefig(f'./img/{i}_.png')




exit()
print(x_train_gray.shape)
print(x_test_gray.shape)

print(x_train_ig.shape)
print(x_test_ig.shape)

# print(model.evaluate(train_ds))
# print(model.evaluate(test_ds))

# train_pred = model.predict(x_train_gray)
# test_pred = model.predict(x_test_gray)

# train_pred = np.argmax(train_pred, axis=1)
# test_pred = np.argmax(test_pred, axis=1)

# from sklearn.metrics import accuracy_score
# print(accuracy_score(train_pred, y_train))
# print(accuracy_score(test_pred, y_test))

# from sklearn.metrics import precision_score
# print(precision_score(train_pred, y_train, pos_label=1))
# print(precision_score(test_pred, y_test, pos_label=1))

# from sklearn.metrics import recall_score
# print(recall_score(train_pred, y_train, pos_label=1))
# print(recall_score(test_pred, y_test, pos_label=1))